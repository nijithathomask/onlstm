{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from embed_regularize import embedded_dropout\n",
    "from locked_dropout import LockedDropout\n",
    "from weight_drop import WeightDrop\n",
    "from ON_LSTM import ONLSTMStack\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, rnn_type, ntoken, ninp, nhid, chunk_size, nlayers, dropout=0.5, dropouth=0.5, dropouti=0.5, dropoute=0.1, wdrop=0, tie_weights=False):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.lockdrop = LockedDropout()\n",
    "        self.idrop = nn.Dropout(dropouti)\n",
    "        self.hdrop = nn.Dropout(dropouth)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        assert rnn_type in ['LSTM'], 'RNN type is not supported'\n",
    "        self.rnn = ONLSTMStack(\n",
    "            [ninp] + [nhid] * (nlayers - 1) + [ninp],\n",
    "            chunk_size=chunk_size,\n",
    "            dropconnect=wdrop,\n",
    "            dropout=dropouth\n",
    "        )\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        # Optionally tie weights as in:\n",
    "        # \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\n",
    "        # https://arxiv.org/abs/1608.05859\n",
    "        # and\n",
    "        # \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)\n",
    "        # https://arxiv.org/abs/1611.01462\n",
    "        if tie_weights:\n",
    "            #if nhid != ninp:\n",
    "            #    raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
    "            self.decoder.weight = self.encoder.weight\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.ninp = ninp\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "        self.dropout = dropout\n",
    "        self.dropouti = dropouti\n",
    "        self.dropouth = dropouth\n",
    "        self.dropoute = dropoute\n",
    "        self.tie_weights = tie_weights\n",
    "\n",
    "    def reset(self):\n",
    "        if self.rnn_type == 'QRNN': [r.reset() for r in self.rnns]\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, input, hidden, return_h=False):\n",
    "        emb = embedded_dropout(\n",
    "            self.encoder, input,\n",
    "            dropout=self.dropoute if self.training else 0\n",
    "        )\n",
    "\n",
    "        emb = self.lockdrop(emb, self.dropouti)\n",
    "\n",
    "        raw_output, hidden, raw_outputs, outputs, distances = self.rnn(emb, hidden)\n",
    "        self.distance = distances\n",
    "\n",
    "        output = self.lockdrop(raw_output, self.dropout)\n",
    "\n",
    "        result = output.view(output.size(0)*output.size(1), output.size(2))\n",
    "        if return_h:\n",
    "            return result, hidden, raw_outputs, outputs\n",
    "        else:\n",
    "            return result, hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        return self.rnn.init_hidden(bsz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
